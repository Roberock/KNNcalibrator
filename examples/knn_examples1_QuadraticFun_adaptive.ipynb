{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def paraboloid_model(theta, xi=0.0, A=1.0, B=0.5, C=1.5):\n",
    "    \"\"\"Vectorized paraboloid, mild noise; supports scalar or vector xi.\"\"\"\n",
    "    theta = np.atleast_2d(theta).astype(float)\n",
    "    x1, x2 = theta[:, 0], theta[:, 1]\n",
    "    xi = np.asarray(xi, float)\n",
    "    if xi.ndim == 0:\n",
    "        xi = np.full(theta.shape[0], xi)\n",
    "    elif xi.ndim == 2:\n",
    "        xi = xi.ravel()\n",
    "    y = A * x1**2 + B * x1 * x2 * (1.0 + xi) + C * (x2 + xi) ** 2\n",
    "    y = y + 0.2 * np.random.randn(theta.shape[0])  # small noise\n",
    "    return y.reshape(-1, 1) if theta.shape[0] > 1 else np.array([y.item()])\n",
    "\n",
    "def theta_sampler(n, lb=-15, ub=15):\n",
    "    return np.random.uniform(lb, ub, size=(n, 2))\n",
    "\n",
    "def scatter_post(ax, theta, truth=None, title=\"\", alpha=0.30, s=6, label=\"Posterior\"):\n",
    "    ax.scatter(theta[:,0], theta[:,1], s=s, alpha=alpha, label=label)\n",
    "    if truth is not None:\n",
    "        ax.scatter(truth[:,0], truth[:,1], c=\"r\", marker=\"x\", s=60, label=\"θ true cloud\")\n",
    "    ax.set_title(title); ax.set_xlabel(\"θ1\"); ax.set_ylabel(\"θ2\"); ax.grid(True); ax.legend()\n"
   ],
   "id": "6e6cebfa4f1b6a02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Adaptive DB expansion for KNN-based calibration\n",
    "\n",
    "\n",
    "A semi Bayesian procedure\n",
    "1. generate $D^{sim} =\\{x_i,y_i\\}_{i=1}^{n_{s}}$ of simulated input-out pairs from a Sim model $M$ sampled according to $f_x(X)$ (prior)\n",
    "2. gather $D^{emp} = \\{y^{emp}_j\\}_{k=1}^{n_{e}}$ of empirical samples from a real system\n",
    "3. for each empirical vector $ y^{emp} \\in D_{emp}$ find a set $\\mathcal{K}(y^{emp})$ with the $k$ input generating the closest output responses $ \\mathcal{K}(y) \\subset D_{sim}$, such that, e.g., $\\sum\\limits_{(x,y)\\in \\mathcal{K}(y^{emp})}||y^{emp}_k - y||_2^2$ is minimized\n",
    "4. combine data in a data set of input $ D_{cal} = \\bigcup \\limits_{y\\in D_{emp}} \\{x \\in \\mathcal{K}(y)\\}$\n",
    "5. use it to fit a non-parametric posterior $f_x(X|D^{emp}) \\propto f_x(X|D_{cal}) f_x(X)$\n",
    "\n",
    "\n",
    "Now extend it so that the D^{sim} is augmented in case the variance of $\\mathcal{K}(y^{emp})$ is too large (or some other approach to reduce sparsity in x)\n",
    "1. generate $D^{sim} =\\{x_i,y_i\\}_{i=1}^{n_{s}}$ of simulated input-out pairs from a Sim model $M$ sampled according to $f_x(X)$ (prior)\n",
    "2. gather $D^{emp} = \\{y^{emp}_j\\}_{k=1}^{n_{e}}$ of empirical samples from a real system\n",
    "3. for each empirical vector $y^{emp} \\in D_{emp}$ find a set $\\mathcal{K}(y^{emp})$ with the $k$ input generating the closest output responses $ \\mathcal{K}(y) \\subset D_{sim}$, such that, e.g., $\\sum\\limits_{(x,y)\\in \\mathcal{K}(y^{emp})}||y^{emp} - y||_2^2$ is minimized\n",
    "4. if the set $\\mathcal{X} =\\{x \\in \\mathcal{K}(y^{emp}) \\} $ has a large variance (in comparison to the other  $y^{emp} \\in D_{emp}$ ). Then resample arround $x$ from $f_x(X)$....assign weights accordingly? then repeat 3? refine the K set"
   ],
   "id": "51c45c8dbcd4dab8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from src.backward import AdaptiveKNNCalibrator\n",
    "from src.dgm import data_generation_mechanism\n",
    "\n",
    "# Example simple simulator (replace with your expensive model)\n",
    "def simulator(X, xi=0.0):\n",
    "    return paraboloid_model(theta=X, xi=xi)\n",
    "\n",
    "# Prior sampler\n",
    "def sample_prior(n):\n",
    "    return theta_sampler(n=n)\n",
    "\n"
   ],
   "id": "a640283fe55550e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    ".Generate empirical evidence (data from an unknown data gen process)\n",
    "\n",
    "* Case 1 - 1 sample (y), 1 target (θ point-valued), 1 experiment (ξ)\n",
    "* Case 2 - 100 samples (y) from 100 samples from the targets (θ distribution), and 1 experiment (ξ)\n",
    "* Case 3 - 100 samples (y) from 100 samples from the target (θ distribution), and for 4 experiments (ξ)"
   ],
   "id": "3b1e1c70575ad4c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "observations_c1 , theta_true_c1= data_generation_mechanism(case = 1)\n",
    "observations_c2 , theta_true_c2= data_generation_mechanism(case = 2)\n",
    "observations_c3 , theta_true_c3= data_generation_mechanism(case = 3)"
   ],
   "id": "2594cdc09b2d00f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_emp, xi = observations_c1[0]\n",
    "cal = AdaptiveKNNCalibrator(simulator=lambda x: simulator(x, xi),\n",
    "                            sample_prior=sample_prior)\n",
    "D_cal1 = cal.run(Y_emp=y_emp, n_s=2500)\n",
    "\n",
    "\n",
    "y_emp, xi = observations_c2[0]\n",
    "cal = AdaptiveKNNCalibrator(simulator=lambda x: simulator(x, xi),\n",
    "                            sample_prior=sample_prior)\n",
    "D_cal2 = cal.run(Y_emp=y_emp, n_s=2500)\n",
    "\n",
    "posterior_list = []\n",
    "for (y_emp, xi) in observations_c3:\n",
    "    cal = AdaptiveKNNCalibrator(simulator=lambda x: simulator(x, xi),\n",
    "                                sample_prior=sample_prior)\n",
    "    D_cal2 = cal.run(Y_emp=y_emp, n_s=2500)\n",
    "    posterior_list.append(D_cal2)\n",
    "\n",
    "# Combine posteriors across experiments (independent designs)\n",
    "#posterior = combine_posteriors(posterior_list)"
   ],
   "id": "8f4f7b60f6b5df23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "alpha=.3\n",
    "plt.scatter(D_cal1[:,0], D_cal1[:,1], alpha=alpha)\n",
    "plt.scatter(theta_true_c1[:,0],theta_true_c1[:,1], alpha=0.9,  c='r')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(D_cal2[:,0], D_cal2[:,1], alpha=alpha)\n",
    "plt.scatter(theta_true_c2[:,0],theta_true_c2[:,1], alpha=0.9, c='r')\n",
    "plt.show()\n",
    "\n",
    "for Dcal in posterior_list:\n",
    "    plt.scatter(Dcal[:,0], Dcal[:,1], alpha=alpha, c='b')\n",
    "    plt.scatter(theta_true_c3[:,0],theta_true_c3[:,1], alpha=0.9,  c='r')\n",
    "plt.show()"
   ],
   "id": "a2370b1c0b321498",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from src.plot import plot_kde_2d , weighted_mixture_kde\n",
    "\n",
    "# --- Plot individual KDEs ---\n",
    "plot_kde_2d(D_cal1, true_theta=theta_true_c1)\n",
    "plot_kde_2d(D_cal2, true_theta=theta_true_c2)\n",
    "\n",
    "# Example weights (uniform)\n",
    "K = len(posterior_list)\n",
    "weights = np.ones(K) / K\n",
    "\n",
    "weighted_mixture_kde(posterior_list, weights, true_theta=theta_true_c3)"
   ],
   "id": "7b524754c5843aca",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
